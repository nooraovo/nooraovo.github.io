---
title:          "Benign Overfitting in Single-Head Attention"
date:           2024-10-10 00:01:00 +0800
selected:       true
# pub:            "International Conference on Machine Learning (ICML)"
# pub_pre:        "Submitted to "
pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
# pub_date:       "2024"

abstract: >-
  We study benign overfitting in single-head attention, the core of Transformers. We show that under certain conditions, the model can fit noisy training data and still generalize well, even after just two steps of gradient descent. Our results highlight the key role of the signal-to-noise ratio in enabling this behavior.
cover:          /assets/images/covers/singlehead.JPG
authors:
  - Roey Magen*
  - Shuning Shang*
  - Zhiwei Xu
  - Spencer Frei
  - Wei Hu†
  - Gal Vardi†
links:
  Paper: https://arxiv.org/abs/2410.07746
---
